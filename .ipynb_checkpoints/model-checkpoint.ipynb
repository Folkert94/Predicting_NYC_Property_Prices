{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler\n",
    "from sklearn.preprocessing.data import normalize\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "df = pd.read_csv(\"sales_data_2015.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning option 1\n",
    "# df2 = df[['borough', 'bldg_cls_p', 'tax_cls_p', 'tot_sqft', 'land_sqft', 'tot_unit', 'res_unit', 'com_unit', 'price']]\n",
    "# df2 = df2[(df2.tot_sqft != 0) & (df2.tot_sqft != 1) & (df2.price >= 100) & (df2.land_sqft != 0)]\n",
    "\n",
    "# df2.dropna(subset = [\"bldg_cls_p\"], inplace=True)\n",
    "# df2.dropna(subset = [\"tax_cls_p\"], inplace=True)\n",
    "\n",
    "# print(\"Length of dataset is {}\".format(len(df2)))\n",
    "\n",
    "# def bldg_cls_simple(building):\n",
    "#     return building[0]\n",
    "\n",
    "# def tax_cls_simple(building):\n",
    "#     return building[0]\n",
    "\n",
    "# df2['cat'] = df2.bldg_cls_p.apply(lambda building: bldg_cls_simple(str(building)))\n",
    "# df2['tax_cat'] = df2.tax_cls_p.apply(lambda building: tax_cls_simple(str(building)))\n",
    "\n",
    "# # df2 = pd.concat([df2, pd.get_dummies(df2.tax_cls_p)], axis=1)\n",
    "# df2 = pd.concat([df2, pd.get_dummies(df2.cat)], axis=1)\n",
    "# df2 = pd.concat([df2, pd.get_dummies(df2.tax_cat)], axis=1)\n",
    "# df2 = pd.concat([df2, pd.get_dummies(df2.borough, prefix=\"b\")], axis=1)\n",
    "\n",
    "# df2 = df2.drop(columns=['bldg_cls_p', 'borough', 'tax_cls_p', 'cat', 'tax_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning option 2 (all possible features)\n",
    "df2 = df[['borough', 'bldg_ctgy','bldg_cls_p', 'tax_cls_p','bldg_cls_s', 'tax_cls_s', 'tot_sqft', 'yr_built', 'land_sqft', 'tot_unit', 'res_unit', 'com_unit', 'price']]\n",
    "df2 = df2[(df2.tot_sqft != 0) & (df2.tot_sqft != 1) & (df2.land_sqft != 0) & (df2.land_sqft != 1) & (df2.price >= 1000) & (df2.land_sqft != 0) & (df2.yr_built !=0)]\n",
    "\n",
    "df2.dropna(subset = [\"bldg_cls_p\"], inplace=True)\n",
    "df2.dropna(subset = [\"tax_cls_p\"], inplace=True)\n",
    "\n",
    "print(\"Length of dataset is {}\".format(len(df2)))\n",
    "\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2.bldg_cls_s, prefix=\"bdgp_cls_s\")], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2.borough, prefix=\"b\")], axis=1)\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2.bldg_ctgy, prefix=\"bldg_ctgy\")], axis=1)\n",
    "# df2 = pd.concat([df2, pd.get_dummies(df2.tax_cls_s, prefix=\"tax_cls_s\")], axis=1)\n",
    "\n",
    "df2 = df2.drop(columns=['borough','bldg_ctgy', 'bldg_cls_p', 'tax_cls_p','bldg_cls_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(columns=['price'])\n",
    "Y = df2.price\n",
    "Y = np.array(Y).reshape(-1)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation parameters\n",
    "\n",
    "def nested_cv(MODEL, PARAMS, X, Y, NUM_TRIALS):\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"At {}th trail\".format(i))\n",
    "        inner_cv = KFold(n_splits=10, random_state=i, shuffle=True)\n",
    "        outer_cv = KFold(n_splits=10, random_state=i, shuffle=True)\n",
    "        feature_scaler = StandardScaler()\n",
    "        X = feature_scaler.fit_transform(X)\n",
    "        model = MODEL\n",
    "\n",
    "        lm = GridSearchCV(estimator=model, param_grid=PARAMS, cv=inner_cv)\n",
    "        mae_score = cross_val_score(lm, X=X, y=Y, cv=outer_cv, scoring='neg_mean_absolute_error')\n",
    "        mae_scores.append([mae_score.mean(), mae_score.std()])\n",
    "        r2_score = cross_val_score(lm, X=X, y=Y, cv=outer_cv, scoring='r2')\n",
    "        r2_scores.append([r2_score.mean(), r2_score.std()])\n",
    "    \n",
    "    return r2_scores, mae_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    corry = np.corrcoef(Y, X[\"{}\".format(column)])[0][1]\n",
    "    if corry < 0.2 and corry > -0.2:\n",
    "#         print(\"removed column {0}, because {1}\".format(column, corry))\n",
    "        X = X.drop(columns=[column])\n",
    "    else:\n",
    "        print(\"keep column \", column, corry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "corr = pd.concat([df2.price, df2[list(X.columns)]], axis=1).corr()\n",
    "heatmap = sns.heatmap(corr, vmin=-1, vmax=1, annot=True)\n",
    "plt.savefig('corr_heatmap.png', dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .30, random_state = 20)\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', rf.score(X_train, y_train))\n",
    "print('Test:', rf.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "model = linear_model.Lasso(tol=1.0, normalize=True)\n",
    "nested_lm = nested_cv(model, parameters, X, Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(nested_lm)\n",
    "print(np.mean(temp[0], axis=0))\n",
    "print(np.mean(temp[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "ridge = Ridge()\n",
    "nested_rlm = nested_cv(ridge, parameters, X, Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(nested_rlm)\n",
    "print(np.mean(temp[0], axis=0))\n",
    "print(np.mean(temp[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 2, stop = 6, num = 2, dtype=int)]\n",
    "\n",
    "parameters = {'n_estimators': n_estimators}\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=1)\n",
    "\n",
    "rf_nested = nested_cv(rf, parameters, X, Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(rf_nested)\n",
    "print(np.mean(temp[0], axis=0))\n",
    "print(np.mean(temp[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "              'hidden_layer_sizes':np.linspace(1, 10, 3, dtype=int)\n",
    "             }\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_nested = nested_cv(mlp, parameters, X, Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(mlp_nested)\n",
    "print(np.mean(temp[0], axis=0))\n",
    "print(np.mean(temp[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .30, random_state = 10)\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.Lasso(tol=1.0, normalize=True)\n",
    "lm.fit(X_train, y_train)\n",
    "print('Train:', lm.score(X_train, y_train))\n",
    "print('Test:', lm.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, lm.predict(X_test))\n",
    "mae_baseline = abs(y_test - y_test.mean()).mean()\n",
    "\n",
    "print('MAE:', mae_model)\n",
    "print('MAE (baseline):', mae_baseline)\n",
    "print('Improvement: {:.2f} %'.format(((mae_model-mae_baseline)/ mae_baseline )* 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='r2', cv=5)\n",
    "\n",
    "ridge_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge_regressor.best_params_, ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model = [y_train.mean()] * len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, mean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test:', ridge_regressor.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, ridge_regressor.predict(X_test))\n",
    "mae_baseline = abs(y_test - y_train.mean()).mean()\n",
    "\n",
    "print('MAE:', mae_model)\n",
    "print('MAE (baseline):', mae_baseline)\n",
    "print('Improvement: {:.2f} %'.format(((mae_model-mae_baseline)/ mae_baseline )* 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(normalize=True)\n",
    "\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring='r2', cv=5)\n",
    "\n",
    "lasso_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_regressor.best_params_, lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test:', lasso_regressor.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, lasso_regressor.predict(X_test))\n",
    "mae_baseline = abs(y_test - y_test.mean()).mean()\n",
    "\n",
    "print('MAE:', mae_model)\n",
    "print('MAE (baseline):', mae_baseline)\n",
    "print('Improvement: {:.2f} %'.format(((mae_model-mae_baseline)/ mae_baseline )* 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "print('Train:', lm.score(X_train, y_train))\n",
    "print('Test:', lm.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, lm.predict(X_test))\n",
    "mae_baseline = abs(y_test - y_train.mean()).mean()\n",
    "\n",
    "print('MAE:', mae_model)\n",
    "print('MAE (baseline):', mae_baseline)\n",
    "print('Improvement: {:.2f} %'.format(((mae_model-mae_baseline)/ mae_baseline )* 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm = LinearRegression(normalize=True)\n",
    "# lm.fit(X_train, y_train)\n",
    "\n",
    "lm = linear_model.Lasso(alpha=20, tol=1.0, normalize=True)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "print('Train:', lm.score(X_train, y_train))\n",
    "print('Test:', lm.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, lm.predict(X_test))\n",
    "mae_baseline = abs(y_test - y_train.mean()).mean()\n",
    "\n",
    "print('MAE:', mae_model)\n",
    "print('MAE (baseline):', mae_baseline)\n",
    "print('Improvement: {:.2f} %'.format(((mae_model-mae_baseline)/ mae_baseline )* 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"sales_data_2015_DF-inception-conv.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.merge(df3, on=['Sale_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = new_df.drop(columns=['Unnamed: 0', 'Sale_id', 'bbl_id_x', 'year', 'block', 'lot','easmnt', 'bldg_cls_p', 'address', 'apt','zip','usable'])\n",
    "df4 = df4[(df4.tot_sqft != 0) & (df4.tot_sqft != 1) & (df4.land_sqft != 0) & (df4.land_sqft != 1) & (df4.price >= 10000) & (df4.land_sqft != 0) & (df4.yr_built != 0)]\n",
    "\n",
    "df4.dropna(subset = [\"bldg_cls_s\"], inplace=True)\n",
    "df4.dropna(subset = [\"tax_cls_s\"], inplace=True)\n",
    "\n",
    "print(\"Length of dataset is {}\".format(len(df2)))\n",
    "\n",
    "df4 = pd.concat([df4, pd.get_dummies(df4.bldg_cls_s, prefix=\"bdgp_cls_s\")], axis=1)\n",
    "df4 = pd.concat([df4, pd.get_dummies(df4.borough, prefix=\"b\")], axis=1)\n",
    "df4 = pd.concat([df4, pd.get_dummies(df4.bldg_ctgy, prefix=\"bldg_ctgy\")], axis=1)\n",
    "# df2 = pd.concat([df2, pd.get_dummies(df2.tax_cls_s, prefix=\"tax_cls_s\")], axis=1)\n",
    "\n",
    "df4 = df4.drop(columns=['borough', 'bldg_ctgy', 'tax_cls_p','bldg_cls_s', 'sale_date', 'long', 'lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4.drop(columns=['price'])\n",
    "Y = df4.price\n",
    "Y = np.array(Y).reshape(-1)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_feats = [str(i) for i in range(0, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    corry = np.corrcoef(Y, X[\"{}\".format(column)])[0][1]\n",
    "    if corry < 0.2 and corry > -0.2 and column not in vis_feats:\n",
    "#         print(\"removed column {0}, because {1}\".format(column, corry))\n",
    "        X = X.drop(columns=[column])\n",
    "    else:\n",
    "        print(\"keep column \", column, corry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .30, random_state = 10)\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='r2', cv=5)\n",
    "ridge_regressor.fit(X_train, y_train)\n",
    "\n",
    "print(ridge_regressor.best_params_, ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test:', ridge_regressor.score(X_test, y_test))\n",
    "\n",
    "mae_model = mean_absolute_error(y_test, ridge_regressor.predict(X_test))\n",
    "mae_baseline = abs(y_test - y_train.mean()).mean()\n",
    "\n",
    "print('MAE:', mae_model)\n",
    "print('MAE (baseline):', mae_baseline)\n",
    "print('Improvement: {:.2f} %'.format(((mae_model-mae_baseline)/ mae_baseline )* 100) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
